{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-04-25T12:46:05.313308Z","iopub.status.busy":"2023-04-25T12:46:05.312737Z","iopub.status.idle":"2023-04-25T12:50:09.973629Z","shell.execute_reply":"2023-04-25T12:50:09.972498Z","shell.execute_reply.started":"2023-04-25T12:46:05.313269Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading data...\n"]}],"source":["from numpy.random import seed\n","seed(1)\n","import tensorflow\n","tensorflow.random.set_seed(2)\n","\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, Embedding\n","from keras.layers import LSTM\n","from nltk.corpus import stopwords\n","import pandas as pd\n","from keras.utils import pad_sequences\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","from keras.preprocessing.text import Tokenizer \n","\n","stops = set(stopwords.words('english'))\n","\n","def load_dataset():\n","    df = pd.read_csv('D:/PESU/NLP/final/dataset/IMDB Dataset.csv')\n","    x_data = df['review']       # Reviews/Input\n","    y_data = df['sentiment']    # Sentiment/Output\n","\n","    # PRE-PROCESS REVIEW\n","    x_data = x_data.replace({'<.*?>': ''}, regex = True)          # remove html tag\n","    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n","    x_data = x_data.apply(lambda review: [w for w in review.split() if w not in stops])  # remove stop words\n","    x_data = x_data.apply(lambda review: [w.lower() for w in review])   # lower case\n","    \n","    # ENCODE SENTIMENT -> 0 & 1\n","    y_data = y_data.replace('positive', 1)\n","    y_data = y_data.replace('negative', 0)\n","\n","    return x_data, y_data\n","\n","x_data, y_data = load_dataset()\n","\n","print('Loading data...')\n","x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["131\n","92511\n","40000 train sequences\n","10000 test sequences\n","Pad sequences (samples x time)\n","x_train shape: (40000, 131)\n","x_test shape: (10000, 131)\n"]}],"source":["def get_max_length():\n","    review_length = []\n","    for review in x_train:\n","        review_length.append(len(review))\n","\n","    return int(np.ceil(np.mean(review_length)))\n","\n","\n","# ENCODE REVIEW\n","token = Tokenizer(lower=False) \n","token.fit_on_texts(x_train)\n","x_train = token.texts_to_sequences(x_train)\n","x_test = token.texts_to_sequences(x_test)\n","\n","max_length = get_max_length()\n","print(max_length)\n","\n","x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n","x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n","\n","total_words = len(token.word_index) + 1\n","print(total_words)\n","\n","print(len(x_train), 'train sequences')\n","print(len(x_test), 'test sequences')\n","\n","print('Pad sequences (samples x time)')\n","print('x_train shape:', x_train.shape)\n","print('x_test shape:', x_test.shape)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Build model...\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 131, 32)           2960352   \n","                                                                 \n"," lstm (LSTM)                 (None, 131, 64)           24832     \n","                                                                 \n"," lstm_1 (LSTM)               (None, 131, 128)          98816     \n","                                                                 \n"," lstm_2 (LSTM)               (None, 131, 128)          131584    \n","                                                                 \n"," lstm_3 (LSTM)               (None, 64)                49408     \n","                                                                 \n"," dense (Dense)               (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 3,265,057\n","Trainable params: 3,265,057\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}],"source":["print('Build model...')\n","\n","# ARCHITECTURE\n","EMBED_DIM = 32\n","LSTM_OUT = 64\n","\n","model = Sequential()\n","model.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n","model.add(LSTM(LSTM_OUT, return_sequences=True))  # returns a sequence of vectors of dimension 32\n","model.add(LSTM(128, return_sequences=True))  # returns a sequence of vectors of dimension 32\n","model.add(LSTM(128, return_sequences=True)) \n","model.add(LSTM(LSTM_OUT))  # return a single vector of dimension 32\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n","\n","print(model.summary())\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/15\n","313/313 [==============================] - 64s 171ms/step - loss: 0.4450 - accuracy: 0.7707 - val_loss: 0.2974 - val_accuracy: 0.8764\n","Epoch 2/15\n","313/313 [==============================] - 52s 166ms/step - loss: 0.2030 - accuracy: 0.9275 - val_loss: 0.3047 - val_accuracy: 0.8811\n","Epoch 3/15\n","313/313 [==============================] - 52s 167ms/step - loss: 0.1189 - accuracy: 0.9618 - val_loss: 0.3613 - val_accuracy: 0.8775\n","Epoch 4/15\n","313/313 [==============================] - 52s 167ms/step - loss: 0.0783 - accuracy: 0.9767 - val_loss: 0.4193 - val_accuracy: 0.8734\n","Epoch 5/15\n","313/313 [==============================] - 52s 167ms/step - loss: 0.0505 - accuracy: 0.9858 - val_loss: 0.4395 - val_accuracy: 0.8678\n","Epoch 6/15\n","313/313 [==============================] - 52s 167ms/step - loss: 0.0512 - accuracy: 0.9859 - val_loss: 0.4928 - val_accuracy: 0.8629\n","Epoch 7/15\n","313/313 [==============================] - 52s 165ms/step - loss: 0.0460 - accuracy: 0.9872 - val_loss: 0.4221 - val_accuracy: 0.8657\n","Epoch 8/15\n","313/313 [==============================] - 52s 166ms/step - loss: 0.0337 - accuracy: 0.9912 - val_loss: 0.5630 - val_accuracy: 0.8578\n","Epoch 9/15\n","313/313 [==============================] - 52s 167ms/step - loss: 0.0227 - accuracy: 0.9943 - val_loss: 0.7261 - val_accuracy: 0.8620\n","Epoch 10/15\n","313/313 [==============================] - 52s 166ms/step - loss: 0.0300 - accuracy: 0.9926 - val_loss: 0.7455 - val_accuracy: 0.8554\n","Epoch 11/15\n","313/313 [==============================] - 53s 168ms/step - loss: 0.0309 - accuracy: 0.9916 - val_loss: 0.6082 - val_accuracy: 0.8619\n","Epoch 12/15\n","313/313 [==============================] - 53s 170ms/step - loss: 0.0195 - accuracy: 0.9952 - val_loss: 0.6366 - val_accuracy: 0.8608\n","Epoch 13/15\n","313/313 [==============================] - 54s 171ms/step - loss: 0.0208 - accuracy: 0.9954 - val_loss: 0.6218 - val_accuracy: 0.8548\n","Epoch 14/15\n","313/313 [==============================] - 54s 173ms/step - loss: 0.0284 - accuracy: 0.9932 - val_loss: 0.6417 - val_accuracy: 0.8548\n","Epoch 15/15\n","313/313 [==============================] - 54s 173ms/step - loss: 0.0331 - accuracy: 0.9915 - val_loss: 0.6359 - val_accuracy: 0.8477\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x2458070db50>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(x_train, y_train, batch_size = 128, epochs = 15, validation_data=(x_test, y_test))"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["79/79 [==============================] - 5s 61ms/step - loss: 0.6359 - accuracy: 0.8477\n","Test score: 0.6359463334083557\n","Test accuracy: 0.8476999998092651\n"]}],"source":["score, acc = model.evaluate(x_test, y_test, batch_size=128)\n","print('Test score:', score)\n","print('Test accuracy:', acc)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: vanillaLSTM\\assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: vanillaLSTM\\assets\n"]}],"source":["model.save('vanillaLSTM')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":4}
